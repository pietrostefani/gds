[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geographic Data Science in R and Python",
    "section": "",
    "text": "Welcome\nThis is the website for the “Geographic Data Science” module ENVS363/563 at the University of Liverpool. This is course designed and delivered by Dr. Elisabetta Pietrostefani and Dr. Carmen Cabrera-Arnau from the Geographic Data Science Lab at the University of Liverpool, United Kingdom. Much of the course material is inspired by Dani Arribas-Bel’s course on Geographic Data Science.\nThis module will introduce students to the field of Geographic Data Science (GDS), a discipline established at the intersection between Geographic Information Science (GIS) and Data Science. The course covers how the modern GIS toolkit can be integrated with Data Science tools to solve practical real-world problems.\nCore to the set of employable skills to be taught in this course is an introduction to programming tools. Students will be able to whether to develop their skills in either R or Python in Lab sessions.\nThe website is free to use and is licensed under the Attribution-NonCommercial-NoDerivatives 4.0 International. A compilation of this web course is hosted as a GitHub repository that you can access:"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Geographic Data Science in R and Python",
    "section": "Contact",
    "text": "Contact\n\nElisabetta Pietrostefani - e.pietrostefani [at] liverpool.ac.uk Lecturer in Geographic Data Science Office 6xx, Roxby Building, University of Liverpool - 74 Bedford St S, Liverpool, L69 7ZT, United Kingdom.\n\n\nCarmen Cabrera-Arnau - c.cabrera-arnau [at] liverpool.ac.uk Lecturer in Geographic Data Science Office 6xx, Roxby Building, University of Liverpool - 74 Bedford St S, Liverpool, L69 7ZT, United Kingdom."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1 Introduction",
    "section": "",
    "text": "Open Science\nWatch: Solving Life’s Everyday Problems with Data"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "openscience.html",
    "href": "openscience.html",
    "title": "1 - Open Science",
    "section": "",
    "text": "Concepts\nThe ideas behind this block are better communicated through narrative than video or lectures. Hence, the concepts section are delivered through a few references you are expected to read. These will total up about one and a half hours of your focused time.\n\n\nOpen Science\nThe first part of this block is about setting the philosophical background. Why do we care about the processes and tools we use when we do computational work? Where do the current paradigm come from? Are we on the verge of a new model? For all of this, we we have two reads to set the tone. Make sure to get those in first thing before moving on to the next bits.\nRead the chapter here. Estimated time: 15min.\n\nFirst half of Chapter 1 in \"Geographic Data Science with PySAL and the PyData stack\" reyABwolf.\n\nRead the piece here. Estimated time: 35min.\n\nThe 2018 Atlantic piece \"The scientific paper is obsolete\" on computational notebooks, by James Somers somers2018scientific.\n\n\n\nModern Scientific Tools\nOnce we know a bit more about why we should care about the tools we use, let's dig into those that will underpin much of this course. This part is interesting in itself, but will also valuable to better understand the practical aspects of the course. Again, we have two reads here to set the tone and complement the practical introduction we saw in the Hands-on and DIY parts of the previous block. We are closing the circle here:\nRead the chapter here.\n\nSecond half of Chapter 1 in \"Geographic Data Science with PySAL and the PyData stack\" reyABwolf.\nThe chapter in the GIS&T Book of Knowledge on computational notebooks, by Geoff Boeing and Dani Arribas-Bel."
  },
  {
    "objectID": "overview.html#aims",
    "href": "overview.html#aims",
    "title": "Overview",
    "section": "Aims",
    "text": "Aims\nThe module has three main aims.\n\nProvide students with core competences in Geographic Data Science (GDS). This includes advancing their statistical and numerical literacy and introducing basic principles of programming and state-of-the-art computational tools for GDS;\nPresent a comprehensive overview of the main methodologies available to the Geographic Data Scientist, as well as their intuition as to how and when they can be applied;\nFocus on real world applications of these techniques in a geographical and applied context."
  },
  {
    "objectID": "overview.html#learning-outcomes",
    "href": "overview.html#learning-outcomes",
    "title": "Overview",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nBy the end of the module, students should be able to:\nFor all\n\nDemonstrate advanced GIS/GDS concepts and be able to use the tools programmatically to import, manipulate and analyse data in different formats.\nUnderstand the motivation and inner workings of the main methodological approaches of GDS, both analytical and visual.\nEvaluate the suitability of a specific technique, what it can offer and how it can help answer questions of interest.\nApply a number of spatial analysis techniques and how to interpret the results, in the process of turning data into information.\nWhen faced with a new data-set, work independently using GIS/GDS tools programmatically.\n\nOnly for MSc students\n\nDemonstrate a sound understanding of how real-world (geo)data are produced, their potential insights and biases, as well as opportunities and limitations."
  },
  {
    "objectID": "overview.html#feedback",
    "href": "overview.html#feedback",
    "title": "Overview",
    "section": "Feedback",
    "text": "Feedback\nFormal assessment of one map, one MCQ test and one computational essays. Written assignment-specific feedback will be provided within three working weeks of the submission deadline. Comments will offer an understanding of the mark awarded and identify areas which can be considered for improvement in future assignments.\nVerbal face-to-face feedback. Immediate face-to-face feedback will be provided during computer, discussion and clinic sessions in interaction with staff. This will take place in all live sessions during the semester.\nOnline forum. Asynchronous written feedback will be provided via an online forum. Students are encouraged to contribute by asking and answering questions relating to the module content. Staff will monitor the forum Monday to Friday 9am-5pm, but it will be open to students to make contributions at all times. Response time will vary depending on the complexity of the question and staff availability."
  },
  {
    "objectID": "overview.html#computational-environment",
    "href": "overview.html#computational-environment",
    "title": "Overview",
    "section": "Computational Environment",
    "text": "Computational Environment\nADD SOMETHING ABOUR R or Python\nEDIT the below\nThis course can be followed by anyone with access to a bit of technical infrastructure. This section details the set of local and online requirements you will need to be able to follow along, as well as instructions or pointers to get set up on your own. This is a centralized section that lists everything you will require, but keep in mind that different blocks do not always require everything all the time.\nTo reproduce the code in the book, you need the most recent version of R and packages. These can be installed following the instructions provided in our R installation guide.\n\nSoftware\nEDIT\nTo run the analysis and reproduce the code, you need the following software:\n\nQGIS- the stable version (3.22 LTR at the time of writing) is OK, any more recent version will also work.\nR-4.2.2\nRStudio 2022.12.0-353\nQuarto 1.2.280\nthe list of libraries in the next section\n\nTo install and update:\n\nQGIS, download the appropriate version from QGIS.org\nR, download the appropriate version from The Comprehensive R Archive Network (CRAN)\nRStudio, download the appropriate version from Posit\nQuarto, download the appropriate version from the Quarto website\n\nTo check your version of:\n\nR and libraries run sessionInfo()\nRStudio click help on the menu bar and then About\nQuarto check the version file in the quarto folder on your computer.\n\n\n\nR List of libraries\nThe list of libraries used in this book is provided below:\n\n\nPython set-up\n\n\nOnline accounts"
  },
  {
    "objectID": "assess.html#assignment-i",
    "href": "assess.html#assignment-i",
    "title": "Assessments",
    "section": "Assignment I",
    "text": "Assignment I\n\nTitle: Programmed Map\nType: Coursework\nDue date: TBC\n25% of the final mark\nChance to be reassessed\nElectronic submission only\n\nThis assignment will be evaluated on technical data processing, map design abilities, and overall narrative.\nFirst, the data.\nSecond, the assemblage.\nThird, the design and overall narrative\nOnce you have created your map, you will need to present it. Write 250 about the choices you made to create the map.\n\nSubmit\nOnce completed, you will need to submit the following:\nAn html version of an .qmd document with R or Python integrated code.\nThe assignment will be evaluated based on four main pillars, on which you will have to be successful to achieve a good mark:\n\nData processing\nMap assemblage This includes your ability to master technologies that allow you to create a compelling map.\nDesign and narrative"
  },
  {
    "objectID": "assess.html#assignment-ii",
    "href": "assess.html#assignment-ii",
    "title": "Assessments",
    "section": "Assignment II",
    "text": "Assignment II\n\nTitle: MCQ test\nType: Test\nDue date: TBC\n25% of the final mark\nChance to be reassessed\nElectronic submission only\n\n\nTo ensure students are engaging with the course content as it progresses and\nTo provide core learning in advance of the third assessment."
  },
  {
    "objectID": "assess.html#marking-criteria",
    "href": "assess.html#marking-criteria",
    "title": "Assessments",
    "section": "Marking Criteria",
    "text": "Marking Criteria\nThis course follows the standard marking criteria (the general ones and those relating to GIS assignments in particular) set by the School of Environmental Sciences. Please make sure to check the student handbook and familiarise with them. In addition to these generic criteria, the following specific criteria will be used in cases where computer code is part of the work being assessed:\n\n0-15: the code does not run and there is no documentation to follow it.\n16-39: the code does not run, or runs but it does not produce the expected outcome. There is some documentation explaining its logic.\n40-49: the code runs and produces the expected output. There is some documentation explaining its logic.\n50-59: the code runs and produces the expected output. There is extensive documentation explaining its logic.\n60-69: the code runs and produces the expected output. There is extensive documentation, properly formatted, explaining its logic.\n70-79: all as above, plus the code design includes clear evidence of skills presented in advanced sections of the course (e.g. custom methods, list comprehensions, etc.).\n80-100: all as above, plus the code contains novel contributions that extend/improve the functionality the student was provided with (e.g. algorithm optimizations, novel methods to perform the task, etc.)."
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Introduction and Open Science\n\nLecture: Introduction to the module & Open Science\nLab: Setting up your Computational Environment & Data Wrangling\n\nSpatial Data\n\nLecture:\nLab:\n\nMapping Vector Data\n\nLecture:\nLab:\n\nMapping Raster Data\n\nLecture:\nLab:\n\nAssignment I: Programmed Map\nSpatial Weights\n\nLecture:\nLab:\n\nESDA\n\nLecture:\nLab:\n\nAssignment II: MCQ test\nClustering\n\nLecture:\nLab:\n\nInterpolation, heatmaps and point patterns\n\nLecture:\nLab:\n\nSpatial Network Analysis\n\nLecture:\nLab:\n\nAssignment III: A computational essay"
  },
  {
    "objectID": "concepts_openscience.html",
    "href": "concepts_openscience.html",
    "title": "Concepts",
    "section": "",
    "text": "bla bla bla"
  },
  {
    "objectID": "concepts_spatialdata.html",
    "href": "concepts_spatialdata.html",
    "title": "Concepts",
    "section": "",
    "text": "bla bla bla"
  },
  {
    "objectID": "concepts_mapvector.html",
    "href": "concepts_mapvector.html",
    "title": "Concepts",
    "section": "",
    "text": "bla bla bla"
  },
  {
    "objectID": "concepts_mapraster.html",
    "href": "concepts_mapraster.html",
    "title": "Concepts",
    "section": "",
    "text": "bla bla bla"
  },
  {
    "objectID": "environR.html#r-list-of-libraries",
    "href": "environR.html#r-list-of-libraries",
    "title": "R",
    "section": "R List of libraries",
    "text": "R List of libraries\nThe list of libraries used in this book is provided below:\n\nsf\ngeojsonsf\nmapview"
  },
  {
    "objectID": "intro.html#what-is-geographic-data-science",
    "href": "intro.html#what-is-geographic-data-science",
    "title": "Introduction",
    "section": "What is Geographic Data Science?",
    "text": "What is Geographic Data Science?\nThe following clip is taken from a keynote response by Dani Arribas-Bel at the first Spatial Data Science Conference, organised by CARTO and held in Brooklyn in 2017. The talk provides a bit of background and context, which will hopefully help you understand a bit better what Geographic Data Science is.\nTOP UP with slide content"
  },
  {
    "objectID": "intro.html#get-ready",
    "href": "intro.html#get-ready",
    "title": "Introduction",
    "section": "Get ready!",
    "text": "Get ready!\nGo the the Computation Environment section"
  },
  {
    "objectID": "intro.html#further-readings",
    "href": "intro.html#further-readings",
    "title": "1  Introduction",
    "section": "2.1 Further readings",
    "text": "2.1 Further readings\nTo get a better picture, the following readings complement the overview provided above very well:\nBonus\nWatch ! All Maps are wrong https://www.youtube.com/watch?v=kIID5FDi2JQ Watch: Solving Life’s Everyday Problems with Data https://www.sciencefriday.com/segments/solving-lifes-everyday-problems-with-data/\nThe chapter is available free online HTML | PDF\n\nThe introductory chapter to “Doing Data Science” schutt2013doing, by Cathy O’Neil and Rachel Schutt is general overview of why we needed Data Science and where if came from.\nA slightly more technical historical perspective on where Data Science came from and where it might go can be found in David Donoho’s recent overview donoho201750.\nA geographic take on Data Science, proposing more interaction between Geography and Data Science singleton2019geographic."
  },
  {
    "objectID": "environ.html#software",
    "href": "environ.html#software",
    "title": "Environment",
    "section": "Software",
    "text": "Software\nTo run the analysis and reproduce the code, you need the following software:\n\nQGIS- the stable version (3.22 LTR at the time of writing) is OK, any more recent version will also work.\nQGIS, download the appropriate version from QGIS.org\nQuarto 1.2.280\nQuarto, download the appropriate version from the Quarto website"
  },
  {
    "objectID": "assess.html#assignment-iii",
    "href": "assess.html#assignment-iii",
    "title": "Assessments",
    "section": "Assignment III",
    "text": "Assignment III\n\nTitle: Computational Essay\nType: Coursework\nDue date: TBC\n50% of the final mark\nChance to be reassessed\nElectronic submission only\n\nA 2500 word computational essay on a geographic data set which they have explored and analysed using the skills and techniques developed during the course. Students will complete an essay which combines both code, data visualisation and prose supported by references in order to demonstrate sound understanding of all learning outcomes.\nOverview\nHere’s the premise. You will take the role of a real-world geographic sata scientist tasked to explore datasets on New York City and find useful insights for a variety of city decision-makers. It does not matter if you have never been to New York City. In fact, this will help you focus on what you can learn about the city through the data, without the influence of prior knowledge. Furthermore, the assessment will not be marked based on how much you know about New York City but instead about how much you can show you have learned through analysing data. You will need contextualise your project by highlighting the opportunities and limitations of ‘old’ and ‘new’ forms of spatial data and reference relevant literature.\nWhat is a Computational Essay?\nA computational essay is an essay whose narrative is supported by code and computational results that are included in the essay itself. This piece of assessment is equivalent to 2,500 word. However, this is the overall weight. Since you will need to create not only narrative but also code and figures, here are the requirements:\n\nMaximum of 1,000 words (ordinary text) (references do not contribute to the word count). You should answer the specified questions within the narrative. The questions should be included within a wider analysis.\nUp to four maps or figures (a figure may include more than one map and will only count as one but needs to be integrated in the same overall output)\nUp to one table\n\nThere are three kinds of elements in a computational essay:\n1. Ordinary text (in English)\n2. Computer input (R-markdown or Python code)\n3. Computer output These three elements all work together to express what’s being communicated.\nSubmission (Coming Soon)\nData (Coming Soon)\nSpecifics (Coming Soon)"
  },
  {
    "objectID": "environ.html#book-software",
    "href": "environ.html#book-software",
    "title": "Environment",
    "section": "Book Software",
    "text": "Book Software\nTo reproduce the code in the book, you need the most recent version of Quarto, R and relevant packages. These can be installed following the instructions provided in our R installation guide. Quarto (1.2.280) can be downloaded from the Quarto website, it may already be installed when you download R and R Studio."
  },
  {
    "objectID": "intro.html#from-geographic-data-science-to-geographic-data-science",
    "href": "intro.html#from-geographic-data-science-to-geographic-data-science",
    "title": "1 Introduction",
    "section": "From Geographic Data Science to Geographic Data Science",
    "text": "From Geographic Data Science to Geographic Data Science\nGeographic Information holds a pivotal position within our modern societies, permeating various aspects of our daily lives. It underpins essential sectors such as housing, transportation, insurance, banking, telecommunications, logistics, energy, retail, agriculture, healthcare, and urban planning. Its significance lies in the capacity to analyze and derive invaluable insights from geo-spatial data, enabling us to make informed decisions and address complex challenges. Proficiency in this field equips individuals with the ability to work with real-world data across multiple domains and tackle diverse problems. Furthermore, it provides the opportunity to acquire essential data science skills and utilize important tools for answering spatial questions. Given its wide-ranging applications and the increasing reliance on location-based information, there is a substantial demand for experts in the geographic information industry, making it a highly sought-after skill set in today’s workforce.\nWhat information does GIS use?\n\nData that defines geographical features like roads, rivers\nSoil types, land use, elevation\nDemographics, socioeconomic attributes\nEnvironmental, climate, air-quality\nAnnotations that label features and places\n\nGeographic Data Science\nA GIS person typically produces cartographic and analytical products using desktop software. A geospatial data scientist creates code and runs pipelines that produce analytical products and cartographic representations.\nThis entails working with real-world data from various domains and tackling a wide range of complex problems. Through this process geospatial data science includes both data science and GIS tools that lead to the analysos of intricate spatial questions effectively. The synergy between CyberGIS and Geographic Data Science is unmistakable, with coding playing a pivotal role in enabling the seamless development of interactive data analysis. By leveraging cutting-edge technologies and innovative methodologies, this symbiotic relationship enhances the accessibility, scalability, and interactivity of geospatial data analysis. Consequently, it opens up new vistas for collaborative research and decision-making processes.\nThis multifaceted approach equips them with the knowledge and expertise to navigate the intricate world of spatial data analysis and contribute meaningfully to diverse fields where location-based insights are invaluable."
  },
  {
    "objectID": "intro.html#a-useful-clip-cannot-find-it",
    "href": "intro.html#a-useful-clip-cannot-find-it",
    "title": "Introduction",
    "section": "A useful clip (cannot find it)",
    "text": "A useful clip (cannot find it)\nThe following clip is taken from a keynote response by Dani Arribas-Bel at the first Spatial Data Science Conference, organised by CARTO and held in Brooklyn in 2017. The talk provides a bit of background and context, which will hopefully help you understand a bit better what Geographic Data Science is."
  },
  {
    "objectID": "intro.html#open-science-1",
    "href": "intro.html#open-science-1",
    "title": "1 Introduction",
    "section": "Open Science",
    "text": "Open Science\nWhy do we care about the processes and tools we use when we do computational work? Where do the current paradigm come from? Are we on the verge of a new model? For all of this, we we have two reads to set the tone. Make sure to get those in first thing before moving on to the next bits.\n\nFirst half of Chapter 1 in “Geographic Data Science with Python” Geographic Thinking for Data Scientists.\nThe 2018 Atlantic piece “The scientific paper is obsolete” on computational notebooks, by James Somers."
  },
  {
    "objectID": "intro.html#modern-scientific-tools",
    "href": "intro.html#modern-scientific-tools",
    "title": "1 Introduction",
    "section": "Modern Scientific Tools",
    "text": "Modern Scientific Tools\nOnce we know a bit more about why we should care about the tools we use, let’s dig into those that will underpin much of this course. This part is interesting in itself, but will also valuable to better understand the practical aspects of the course. Again, we have two reads here to set the tone and complement the practical introduction we saw in the Hands-on and DIY parts of the previous block. We are closing the circle here:\n\nSecond half of Chapter 1 in “Geographic Data Science with Python” Geographic Thinking for Data Scientists."
  },
  {
    "objectID": "spatialdata.html",
    "href": "spatialdata.html",
    "title": "Spatial Data",
    "section": "",
    "text": "Watch ! All Maps are wrong https://www.youtube.com/watch?v=kIID5FDi2JQ"
  },
  {
    "objectID": "environPy.html",
    "href": "environPy.html",
    "title": "Python",
    "section": "",
    "text": "Resources\nSome help along the way with:\n\nGeographic Data Science with Python by Sergio J. Rey, Dani Arribas-Bel, Levi J. Wolf"
  },
  {
    "objectID": "environR.html",
    "href": "environR.html",
    "title": "R",
    "section": "",
    "text": "Resources\nSome help along the way with:"
  },
  {
    "objectID": "openscienceR.html",
    "href": "openscienceR.html",
    "title": "1  | include: false",
    "section": "",
    "text": "OpenScience in R\nOnce we know a bit about what computational notebooks are and why we should care about them, let’s jump to using them! This section introduces you to using R or Python for manipulating tabular data. Please read through it carefully and pay attention to how ideas about manipulating data are translated into code that “does stuff”. For this part, you can read directly from the course website, although it is recommended you follow the section interactively by running code on your own.\nOnce you have read through and have a bit of a sense of how things work, jump on the Do-It-Yourself section, which will provide you with a challenge to complete it on your own, and will allow you to put what you have already learnt to good use."
  },
  {
    "objectID": "openscienceR.html#data-wrangling",
    "href": "openscienceR.html#data-wrangling",
    "title": "OpenScience in R",
    "section": "Data wrangling",
    "text": "Data wrangling\nReal world datasets are messy. There is no way around it: datasets have “holes” (missing data), the amount of formats in which data can be stored is endless, and the best structure to share data is not always the optimum to analyze them, hence the need to munge them. As has been correctly pointed out in many outlets (e.g.), much of the time spent in what is called (Geo-)Data Science is related not only to sophisticated modeling and insight, but has to do with much more basic and less exotic tasks such as obtaining data, processing, turning them into a shape that makes analysis possible, and exploring it to get to know their basic properties.\nFor how labor intensive and relevant this aspect is, there is surprisingly very little published on patterns, techniques, and best practices for quick and efficient data cleaning, manipulation, and transformation. In this session, you will use a few real world datasets and learn how to process them into Python so they can be transformed and manipulated, if necessary, and analyzed. For this, we will introduce some of the bread and butter of data analysis and scientific computing in Python. These are fundamental tools that are constantly used in almost any task relating to data analysis.\nThis notebook covers the basic and the content that is expected to be learnt by every student. We use a prepared dataset that saves us much of the more intricate processing that goes beyond the introductory level the session is aimed at. As a companion to this introduction, there is an additional notebook (see link on the website page for Lab 01) that covers how the dataset used here was prepared from raw data downloaded from the internet, and includes some additional exercises you can do if you want dig deeper into the content of this lab.\nIn this notebook, we discuss several patterns to clean and structure data properly, including tidying, subsetting, and aggregating; and we finish with some basic visualization. An additional extension presents more advanced tricks to manipulate tabular data.\nBefore we get our hands data-dirty, let us import all the additional libraries we will need, so we can get that out of the way and focus on the task at hand:"
  },
  {
    "objectID": "openscienceR.html#loading-packages",
    "href": "openscienceR.html#loading-packages",
    "title": "OpenScience in R",
    "section": "Loading packages",
    "text": "Loading packages\nWe will start by loading core packages for working with geographic vector and attribute data.\n\nPythonR\n\n\n\n\n\n\n\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2\n──\n\n\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.3.0      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(tmap)"
  },
  {
    "objectID": "syllabus.html#part-1",
    "href": "syllabus.html#part-1",
    "title": "Syllabus",
    "section": "Part 1",
    "text": "Part 1\nIntroduction and Open Science\n\nLecture: Introduction to the module & Open Science\nLab: Setting up your Computational Environment & Data Wrangling\n\nSpatial Data\n\nLecture:\nLab:\n\nMapping Vector Data\n\nLecture:\nLab:\n\nMapping Raster Data\n\nLecture:\nLab:\n\nAssignment I: Programmed Map"
  },
  {
    "objectID": "syllabus.html#part-2",
    "href": "syllabus.html#part-2",
    "title": "Syllabus",
    "section": "Part 2",
    "text": "Part 2\nSpatial Weights\n\nLecture:\nLab:\n\nESDA\n\nLecture:\nLab:\n\nAssignment II: MCQ test\nClustering\n\nLecture:\nLab:\n\nInterpolation, heatmaps and point patterns\n\nLecture:\nLab:\n\nSpatial Network Analysis\n\nLecture:\nLab:\n\nAssignment III: A computational essay"
  },
  {
    "objectID": "openscienceDIY.html#import-libraries",
    "href": "openscienceDIY.html#import-libraries",
    "title": "Do-It-Yourself",
    "section": "Import libraries",
    "text": "Import libraries\n\nPythonR\n\n\n\n\n\n\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2\n──\n\n\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.3.0      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(tmap)"
  },
  {
    "objectID": "openscienceDIY.html#tasks",
    "href": "openscienceDIY.html#tasks",
    "title": "Do-It-Yourself",
    "section": "Tasks",
    "text": "Tasks\nNow, the challenge is to put to work what we have learnt in this block. For that, the suggestion is that you carry out an analysis of the Afghan Logs in a similar way as how we looked at population composition in Liverpool. These are of course very different datasets reflecting immensely different realities. Their structure, however, is relatively parallel: both capture counts aggregated by a spatial (neighbourhood) or temporal unit (month), and each count is split by a few categories.\nTry to answer the following questions:\n\nObtain the minimum number of civilian casualties (in what month was that?)\nHow many NATO casualties were registered in August 2008?\nWhat is the month with the most total number of casualties?\nCan you make a plot of the distribution of casualties over time?\n\nTip: You will need to first create a column with total counts"
  },
  {
    "objectID": "openscience.html#data-wrangling",
    "href": "openscience.html#data-wrangling",
    "title": "OpenScience",
    "section": "Data wrangling",
    "text": "Data wrangling\nReal world datasets are messy. There is no way around it: datasets have “holes” (missing data), the amount of formats in which data can be stored is endless, and the best structure to share data is not always the optimum to analyze them, hence the need to wrangle (manipulating, transforming & structuring) them. As has been correctly pointed out in many outlets (e.g.), much of the time spent in what is called (Geo-)Data Science is related not only to sophisticated modeling and insight, but has to do with much more basic and less exotic tasks such as obtaining data, processing, turning them into a shape that makes analysis possible, and exploring it to get to know their basic properties.\nIn this session, you will use a few real world datasets and learn how to process them in R or Python so they can be transformed and manipulated, if necessary, and analyzed. For this, we will introduce some of the bread and butter of data analysis and scientific computing. These are fundamental tools that are constantly used in almost any task relating to data analysis.\nThis notebook covers the basic and the content that is expected to be learnt by every student. We use a prepared dataset that saves us much of the more intricate processing that goes beyond the introductory level the session is aimed at.\nIn this notebook, we discuss several patterns to clean and structure data properly, including tidying, subsetting, and aggregating; and we finish with some basic visualization. An additional extension presents more advanced tricks to manipulate tabular data.\nBefore we get our hands data-dirty, let us import all the additional libraries we will need, so we can get that out of the way and focus on the task at hand:"
  },
  {
    "objectID": "openscience.html#loading-packages",
    "href": "openscience.html#loading-packages",
    "title": "OpenScience",
    "section": "Loading packages",
    "text": "Loading packages\nWe will start by loading core packages for working with geographic vector and attribute data.\n\nRPython\n\n\n\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(data.table)"
  },
  {
    "objectID": "openscience.html#datasets",
    "href": "openscience.html#datasets",
    "title": "OpenScience",
    "section": "Datasets",
    "text": "Datasets\nWe will be exploring some demographic characteristics in Liverpool. To do that, we will use a dataset that contains population counts, split by ethnic origin. These counts are aggregated at the Lower Layer Super Output Area (LSOA from now on). LSOAs are an official Census geography defined by the Office of National Statistics. You can think of them, more or less, as neighbourhoods. Many data products (Census, deprivation indices, etc.) use LSOAs as one of their main geographies.\nTo make things easier, we will read data from a file posted online so, for now, you do not need to download any dataset:\nImport housesales data from csv\n\nRPython\n\n\n\ncensus2021 <- read.csv(\"data/census2021_ethn/liv_pop.csv\", row.names = \"GeographyCode\")\n\nLet us stop for a minute to learn how we have read the file. Here are the main aspects to keep in mind:\n\nWe are using the method read.csv from base R, you could also use read_csv from library(\"readr\")\nHere the csv is based in the file data but it could also be a web address or sometimes you find data in packages\nThe argument row.names is not strictly necessary but allows us to choose one of the columns as the index of the table. More on indices below.\nWe are using read.csv because the file we want to read is in the csv format. However, many more formats can be read into an R environment. A full list of formats supported may be found here.\n\n\n\n\n\n\nLet us stop for a minute to learn how we have read the file. Here are the main aspects to keep in mind:\n\nWe are using the method read_csv from the pandas library, which we have imported with the alias pd.\nIn this form, all that is required is to pass the path to the file we want to read, which in this case is a web address.\nThe argument index_col is not strictly necessary but allows us to choose one of the columns as the index of the table. More on indices below.\nWe are using read_csv because the file we want to read is in the csv format. However, pandas allows for many more formats to be read and write. A full list of formats supported may be found here.\n\nTo ensure we can access the data we have read, we store it in an object that we call db. We will see more on what we can do with it below but, for now, just keep in mind that allows us to save the result of read_csv.\n\n\n\nTo ensure we can access the data we have read, we store it in an object that we call census2021. We will see more on what we can do with it below but, for now, just keep in mind that allows us to save the result of read.csv.\nImportant You need to store the data file on your computer, and read it locally. To do that, you can follow these steps: 1. Download the file by right-clicking on this link and saving the file (add link) 2. Place the file on the same folder as the notebook where you intend to read it"
  },
  {
    "objectID": "openscience.html#data-sliced-and-diced",
    "href": "openscience.html#data-sliced-and-diced",
    "title": "OpenScience",
    "section": "Data, sliced and diced",
    "text": "Data, sliced and diced\nNow we are ready to start playing and interrogating the dataset! What we have at our fingertips is a table that summarizes, for each of the LSOAs in Liverpool, how many people live in each, by the region of the world where they were born. We call these tables DataFrame objects, and they have a lot of functionality built-in to explore and manipulate the data they contain. Let’s explore a few of those cool tricks!\nStructure\nThe first aspect worth spending a bit of time is the structure of a DataFrame. We can print it by simply typing its name:\n\nRPython\n\n\n\ncensus2021\n\n          Europe Africa Middle.East.and.Asia The.Americas.and.the.Caribbean\nE01006512    910    106                  840                             24\nE01006513   2225     61                  595                             53\nE01006514   1786     63                  193                             61\nE01006515    974     29                  185                             18\nE01006518   1531     69                   73                             19\nE01006519   1238      7                   24                             14\nE01006520   1607     31                   36                             26\nE01006521   1540     35                   62                             18\nE01006522   1632     19                   58                             13\nE01006523   1436     25                   31                             11\nE01006524   2235     36                  125                             24\nE01006525   1173      3                   28                              3\nE01006526   1359      6                   31                              5\nE01006527   1415      5                   20                             10\nE01006528   1378     35                   38                              9\nE01006529   1248     15                   31                              9\nE01006530   1411      3                   11                              4\nE01006531   1427     18                   10                              1\nE01006532   1466     20                   63                              4\nE01006533   1361      2                   41                              3\nE01006534   1441     13                   75                             12\nE01006535   1597     13                   22                              6\nE01006536   1799     12                   27                              9\nE01006537   2180     23                   46                              6\nE01006538   1303      4                    8                              3\nE01006539   1359     11                   54                              9\nE01006540   1394     47                   63                              5\nE01006541   1577      7                    6                              3\nE01006542   1367     10                   12                              5\nE01006543   1242      3                    2                              0\nE01006544   1637      5                   15                              1\nE01006545   1485      4                   16                              7\nE01006546   1282     13                   21                              3\nE01006547   1407     22                   59                              1\nE01006548   1580     51                   36                              7\nE01006549   1387    122                  120                             29\nE01006550   1512     16                   53                             13\nE01006551   1456     42                   63                             19\nE01006552   1406    198                  408                             16\nE01006553   1763     23                   69                             14\nE01006554   1561     30                   78                             16\nE01006556   1417    213                  338                             41\nE01006557   1863     44                  118                             22\nE01006558   1315      6                   31                              5\nE01006560   1776     38                   37                              8\nE01006562   1450     25                   35                              3\nE01006563   1656     32                   45                             10\nE01006564   1660     13                   47                              1\nE01006565   1497      5                   44                              2\nE01006566   1449     26                   29                              2\nE01006567   1600     13                   38                              3\nE01006568   1579     23                    8                              2\nE01006569   1418      7                    2                              1\nE01006570   1445      3                   27                              4\nE01006571   1446     11                   11                              1\nE01006572   1184     11                   11                              1\nE01006573   1446      9                   41                              4\nE01006574   1355     11                   19                              3\nE01006575   1253      5                   27                              5\nE01006576   1666      1                   23                              3\nE01006577   1470     11                   19                              3\nE01006578   1341      4                   30                              3\nE01006579   1597     10                   33                              1\nE01006580   1281      6                   42                              5\nE01006581   1512      6                   27                              8\nE01006582   1587      4                   38                             11\nE01006583   1712      5                   30                              8\nE01006584   1374      7                   10                              0\nE01006585   1287     25                   41                              0\nE01006586   1803     19                   70                              4\nE01006587   1542     26                   46                              8\nE01006588   1500     15                   41                             10\nE01006589   1459      6                   47                              6\nE01006590   1582      8                   38                             10\nE01006591   1540     21                   49                             22\nE01006592   1518     15                   23                              7\nE01006593   1476     17                   36                             12\nE01006594   1307     13                   77                              8\nE01006595   1686     14                   35                              7\nE01006596   1379      8                   57                              5\nE01006597   1612     15                   35                              4\nE01006598   1338      8                   12                              3\nE01006599   1093     18                   10                              0\nE01006600   1395      7                    4                              1\nE01006603   1396      5                    9                              0\nE01006604   1356      6                    4                              1\nE01006605   1509      8                   11                              3\nE01006606   1497     10                   12                              2\nE01006607   1527      1                    2                              1\nE01006608   1207      2                    4                              1\nE01006609   1257      5                   20                              0\nE01006610   1372      7                   12                              4\nE01006611   1274     10                    6                              1\nE01006612   1480      7                    5                              3\nE01006613   1346      2                    9                              2\nE01006614   1300      2                   18                              2\nE01006615   1283      3                   11                              3\nE01006616   1403      7                   15                              3\nE01006617   1392     10                   17                              2\nE01006618   1634      2                    2                              1\nE01006619   1586      4                    8                              1\nE01006620   1400      4                   12                              1\nE01006621   1409     19                   37                              1\nE01006622   1508      1                    9                              1\nE01006623   1396      8                   56                              1\nE01006624   1489     25                   39                              3\nE01006625   1398      3                   11                              4\nE01006626   1418      5                   20                              4\nE01006627   1344     12                   18                              3\nE01006628   1750     39                   59                             21\nE01006629   1200      8                   38                              8\nE01006630   1239     44                   47                              8\nE01006632   1711     49                   78                              3\nE01006633   1415      0                   11                              5\nE01006637   1480     62                   53                              0\nE01006638   1154     24                   41                              0\nE01006639   1461     11                   34                              1\nE01006640   1807     15                   48                              8\nE01006641   1527     20                  191                              0\nE01006642   1253     10                   26                              0\nE01006643   1754     21                   45                              2\nE01006644   1980     24                   30                              3\nE01006645   1396     20                    6                              1\nE01006646   1760     34                   89                             10\nE01006647   1392     17                   12                              1\nE01006648   2034     33                   89                             16\nE01006651   1605      9                   21                              3\nE01006652   1459      1                   45                              0\nE01006653   1479      1                   35                              5\nE01006654   1468      2                   40                              1\nE01006655   1624     21                  107                              6\nE01006656   1478      8                    6                              0\nE01006657   1188      2                   18                              3\nE01006658   1272      3                   24                              1\nE01006659   1687     24                   44                              9\nE01006660   1319      6                  106                              2\nE01006661   1605     33                   21                              4\nE01006662   1710     21                   43                              1\nE01006663   1125      7                   20                              1\nE01006664   1726     23                   38                              5\nE01006665   1523      8                   22                              2\nE01006666   1426     14                   58                              4\nE01006667   1418      8                   22                              3\nE01006668   1485      6                   37                              1\nE01006669   1376     31                   60                              0\nE01006670   1477      4                   43                              1\nE01006671   1280     15                   56                              2\nE01006672   1899     14                   36                              3\nE01006673   1350    273                  269                             42\nE01006674   1197    342                  325                             21\nE01006675   1491    115                  171                             44\nE01006676   1303    203                  215                             28\nE01006677    813    100                  119                              7\nE01006678   1906     92                  108                             18\nE01006679   1353    484                  354                             31\nE01006680   1528      8                   30                              1\nE01006681   1513      7                   60                              4\nE01006682   1282      3                   17                              6\nE01006683   1481      2                   24                              3\nE01006684   2074     10                   42                              8\nE01006685   1451     14                   13                              5\nE01006686   1389     14                   20                             10\nE01006687   1824     53                   61                             11\nE01006688   1486     10                   15                             10\nE01006689   1613     14                   13                              7\nE01006690   1309     85                   82                             14\nE01006691   1147    170                  172                             10\nE01006692   1979    115                   73                             11\nE01006693   1401     27                   76                              6\nE01006694   1452    306                   97                              7\nE01006695   1525    166                  114                             16\nE01006696   1438    135                  165                              4\nE01006697   1506    145                  175                             18\nE01006698   1694      6                   12                              4\nE01006699   1565     23                    4                              2\nE01006700   1392      9                   31                              5\nE01006701   1347      5                   23                              5\nE01006702   1561     22                   35                              0\nE01006703   1509     35                   15                              2\nE01006705   1368     22                   16                              1\nE01006706   1323      9                    8                              6\nE01006707   1298     11                    7                              7\nE01006708   1791      3                    6                              5\nE01006709   1423      1                    8                              2\nE01006710   1474      9                    5                              7\nE01006711   1444     30                   55                              8\nE01006712   1292      0                   45                              1\nE01006713   1329     10                   32                              6\nE01006716   1496     12                   74                              3\nE01006717   1381     19                   27                              8\nE01006718   1533     14                   34                              3\nE01006719   1518      2                   14                              1\nE01006720   1670    153                  263                             14\nE01006721   1480     39                  118                             17\nE01006722   1505     83                  185                             16\nE01006723   1655     49                  141                             27\nE01006724   1641     37                   90                             18\nE01006725   1446     25                   58                              5\nE01006726   1365     63                  121                             13\nE01006727   1360     28                   40                              9\nE01006728   1497     34                   78                             14\nE01006729   1373     16                    7                              2\nE01006730   1303     10                    8                              1\nE01006731   1160      9                   23                              1\nE01006732   1615     10                   13                              5\nE01006734   1371     19                   17                              2\nE01006735   1262      9                   33                              4\nE01006736   1423     20                   13                              3\nE01006737   1409     19                    7                              0\nE01006738   1484      9                    6                              2\nE01006739   1726     19                   20                              4\nE01006740   1226      5                   41                              8\nE01006741   1796      4                    7                              7\nE01006742   1381      4                    6                              2\nE01006743   2102     15                   45                             11\nE01006744   1461      8                    9                              3\nE01006745   1838      4                   30                              7\nE01006746   1327     44                  136                              4\nE01006747   2551    163                  812                             24\nE01006748   1558     60                  272                             40\nE01006751   1843    139                  568                             21\nE01006752    789     62                  152                              8\nE01006753   1532     16                    8                              1\nE01006754   1613     10                    1                              3\nE01006755   1540     23                   12                             12\nE01006756   1768     25                   21                              5\nE01006757   1475      7                    6                              3\nE01006758   1487     23                   16                              1\nE01006759   1034     28                   26                              6\nE01006760   1462     71                   63                             10\nE01006761   1553      7                   81                              3\nE01006762   1649      7                   31                              1\nE01006763   1441     16                   11                              1\nE01006764   1428     36                   51                              5\nE01006765   1439      8                   17                              2\nE01006766   1175     43                   41                              5\nE01006767   1673     63                   41                              6\nE01006768   1273     14                   66                              6\nE01006769   1233      9                   21                              6\nE01006770    977      2                   17                              6\nE01006771   1407      9                    8                              0\nE01006772   1059      6                   22                              2\nE01006773   1354      5                   15                              4\nE01006774   1340     13                   83                              7\nE01006775   1295      3                   14                              6\nE01006776   1637     13                   20                              4\nE01006778   2107     51                   37                              9\nE01006779   1949      6                   11                              2\nE01006780   1442      7                   10                              4\nE01006781   1454      0                   10                              1\nE01006782   1535      5                   20                              0\nE01006783   1516      6                   22                              2\nE01006784   1325      4                   18                              0\nE01006785   1718     34                   12                              3\nE01006786   1795      5                   15                              5\nE01006787   2187     53                   75                             13\nE01006788   1788      6                   26                              3\nE01006790   1556     15                   12                              3\nE01006791   1620     24                   18                             12\nE01006792   1319     16                   29                              3\nE01006793   1428     14                   41                              5\nE01006794   1521     15                   36                             16\nE01006795   1370      1                   24                             10\nE01006796   1461      6                  103                             19\nE01006797   1469      7                   11                              7\nE01006798   1367      7                   27                              9\nE01006799   1779     11                   19                              8\nE01006800   1323     14                   55                              7\nE01006801   1321      4                   26                              3\nE01032505   1254      4                   53                              4\nE01032506   1349     11                   35                              4\nE01032507   1496     11                   14                             14\nE01032508   1602     22                   93                              4\nE01032509   1385     18                   27                              3\nE01032510   1752     18                   33                              5\nE01032511   1355     11                    9                              1\nE01033747    970     16                   45                              9\nE01033748   1157     40                   63                             15\nE01033749   1023     33                   73                             24\nE01033750   1235     53                  129                             26\nE01033751   1674     64                   99                             35\nE01033752   1024     19                  114                             33\nE01033753    869     24                  129                             22\nE01033754   1262     37                  112                             32\nE01033755    952     22                   85                             14\nE01033756    886     31                  221                             42\nE01033757    731     39                  223                             29\nE01033758   1107     50                  557                             14\nE01033759   1097     27                   20                              1\nE01033760   1734     37                  312                             28\nE01033761   1138     52                  138                             33\nE01033762   1570     53                  155                             10\nE01033763   1302     68                  142                             11\nE01033764   2106     32                   49                             15\nE01033765   1277     21                   33                             17\nE01033766   1028     12                   20                              8\nE01033767   1003     29                   29                              5\nE01033768   1016     69                  111                             21\n          Antarctica.and.Oceania\nE01006512                      0\nE01006513                      7\nE01006514                      5\nE01006515                      2\nE01006518                      4\nE01006519                      3\nE01006520                      6\nE01006521                      5\nE01006522                      9\nE01006523                      5\nE01006524                     11\nE01006525                      2\nE01006526                      3\nE01006527                      4\nE01006528                      1\nE01006529                      1\nE01006530                      2\nE01006531                      2\nE01006532                      4\nE01006533                      1\nE01006534                      1\nE01006535                      1\nE01006536                      1\nE01006537                      2\nE01006538                      0\nE01006539                      4\nE01006540                      0\nE01006541                      0\nE01006542                      3\nE01006543                      0\nE01006544                      0\nE01006545                      0\nE01006546                      0\nE01006547                      1\nE01006548                      1\nE01006549                      4\nE01006550                      1\nE01006551                      1\nE01006552                      1\nE01006553                     11\nE01006554                      7\nE01006556                      2\nE01006557                      7\nE01006558                      0\nE01006560                      1\nE01006562                      1\nE01006563                      0\nE01006564                      0\nE01006565                      1\nE01006566                      0\nE01006567                      1\nE01006568                      5\nE01006569                      1\nE01006570                      0\nE01006571                      1\nE01006572                      0\nE01006573                      1\nE01006574                      0\nE01006575                      4\nE01006576                      0\nE01006577                      0\nE01006578                      2\nE01006579                      2\nE01006580                      1\nE01006581                      6\nE01006582                      2\nE01006583                      3\nE01006584                      2\nE01006585                      1\nE01006586                      3\nE01006587                      2\nE01006588                      3\nE01006589                      0\nE01006590                      4\nE01006591                      1\nE01006592                      2\nE01006593                      0\nE01006594                      5\nE01006595                      3\nE01006596                      2\nE01006597                      1\nE01006598                      0\nE01006599                      0\nE01006600                      0\nE01006603                      0\nE01006604                      0\nE01006605                      0\nE01006606                      0\nE01006607                      0\nE01006608                      1\nE01006609                      1\nE01006610                      2\nE01006611                      0\nE01006612                      0\nE01006613                      1\nE01006614                      0\nE01006615                      2\nE01006616                      0\nE01006617                      0\nE01006618                      0\nE01006619                      0\nE01006620                      0\nE01006621                      2\nE01006622                      0\nE01006623                      1\nE01006624                      0\nE01006625                      0\nE01006626                      1\nE01006627                      1\nE01006628                      5\nE01006629                      1\nE01006630                      0\nE01006632                      1\nE01006633                      1\nE01006637                      1\nE01006638                      0\nE01006639                      2\nE01006640                      2\nE01006641                      2\nE01006642                      1\nE01006643                      0\nE01006644                      3\nE01006645                      1\nE01006646                      6\nE01006647                      0\nE01006648                      3\nE01006651                      4\nE01006652                      0\nE01006653                      0\nE01006654                      2\nE01006655                      0\nE01006656                      1\nE01006657                      0\nE01006658                      0\nE01006659                      1\nE01006660                      0\nE01006661                      0\nE01006662                      0\nE01006663                      0\nE01006664                      3\nE01006665                      0\nE01006666                      2\nE01006667                      2\nE01006668                      5\nE01006669                      3\nE01006670                      1\nE01006671                      2\nE01006672                      3\nE01006673                      3\nE01006674                      0\nE01006675                      3\nE01006676                      4\nE01006677                      1\nE01006678                      3\nE01006679                     10\nE01006680                      2\nE01006681                      1\nE01006682                      2\nE01006683                      0\nE01006684                      4\nE01006685                      1\nE01006686                      0\nE01006687                      3\nE01006688                      3\nE01006689                      4\nE01006690                      2\nE01006691                      4\nE01006692                      2\nE01006693                      1\nE01006694                      2\nE01006695                      0\nE01006696                      2\nE01006697                      1\nE01006698                      0\nE01006699                      0\nE01006700                      1\nE01006701                      0\nE01006702                      0\nE01006703                      0\nE01006705                      2\nE01006706                      0\nE01006707                      0\nE01006708                      0\nE01006709                      4\nE01006710                      1\nE01006711                      1\nE01006712                      1\nE01006713                      0\nE01006716                      4\nE01006717                      1\nE01006718                      3\nE01006719                      0\nE01006720                      8\nE01006721                      1\nE01006722                      4\nE01006723                      3\nE01006724                      4\nE01006725                      3\nE01006726                      3\nE01006727                      4\nE01006728                      0\nE01006729                      2\nE01006730                      4\nE01006731                      3\nE01006732                      0\nE01006734                      3\nE01006735                      1\nE01006736                      1\nE01006737                      0\nE01006738                      0\nE01006739                      0\nE01006740                      0\nE01006741                      1\nE01006742                      1\nE01006743                      2\nE01006744                      1\nE01006745                      0\nE01006746                      2\nE01006747                      2\nE01006748                      6\nE01006751                      1\nE01006752                      1\nE01006753                      0\nE01006754                      0\nE01006755                      0\nE01006756                      1\nE01006757                      0\nE01006758                      0\nE01006759                      1\nE01006760                      5\nE01006761                      0\nE01006762                      4\nE01006763                      2\nE01006764                      2\nE01006765                      2\nE01006766                      2\nE01006767                      4\nE01006768                      0\nE01006769                      1\nE01006770                      0\nE01006771                      1\nE01006772                      2\nE01006773                      1\nE01006774                      2\nE01006775                      1\nE01006776                      3\nE01006778                      1\nE01006779                      0\nE01006780                      2\nE01006781                      5\nE01006782                      0\nE01006783                      2\nE01006784                      0\nE01006785                      2\nE01006786                      0\nE01006787                      2\nE01006788                      2\nE01006790                      1\nE01006791                      0\nE01006792                      1\nE01006793                      6\nE01006794                      5\nE01006795                      2\nE01006796                      2\nE01006797                      5\nE01006798                      0\nE01006799                      4\nE01006800                      2\nE01006801                      1\nE01032505                      2\nE01032506                      4\nE01032507                      4\nE01032508                      2\nE01032509                      1\nE01032510                      1\nE01032511                      2\nE01033747                      3\nE01033748                      2\nE01033749                      0\nE01033750                      5\nE01033751                      1\nE01033752                      6\nE01033753                      7\nE01033754                      9\nE01033755                      9\nE01033756                      5\nE01033757                      3\nE01033758                      2\nE01033759                      2\nE01033760                      4\nE01033761                     11\nE01033762                      3\nE01033763                      4\nE01033764                      0\nE01033765                      3\nE01033766                      7\nE01033767                      1\nE01033768                      6\n\n\n\n\n\n\n\n\nNote the printing is cut to keep a nice and compact view, but enough to see its structure. Since they represent a table of data, DataFrame objects have two dimensions: rows and columns. Each of these is automatically assigned a name in what we will call its index. When printing, the index of each dimension is rendered in bold, as opposed to the standard rendering for the content. In the example above, we can see how the column index is automatically picked up from the .csv file’s column names. For rows, we have specified when reading the file we wanted the column GeographyCode, so that is used. If we hadn’t specified any, pandas will automatically generate a sequence starting in 0 and going all the way to the number of rows minus one. This is the standard structure of a DataFrame object, so we will come to it over and over. Importantly, even when we move to spatial data, our datasets will have a similar structure.\nOne final feature that is worth mentioning about these tables is that they can hold columns with different types of data. In our example, this is not used as we have counts (or int, for integer, types) for each column. But it is useful to keep in mind we can combine this with columns that hold other type of data such as categories, text (str, for string), dates or, as we will see later in the course, geographic features.\nInspecting what it looks like. We can check the top (bottom) X lines of the table by passing X to the method head (tail). For example, for the top/bottom five lines: Or getting an overview of the table:\n\nRPython\n\n\n\nhead(census2021) # read first 5 rows\n\n          Europe Africa Middle.East.and.Asia The.Americas.and.the.Caribbean\nE01006512    910    106                  840                             24\nE01006513   2225     61                  595                             53\nE01006514   1786     63                  193                             61\nE01006515    974     29                  185                             18\nE01006518   1531     69                   73                             19\nE01006519   1238      7                   24                             14\n          Antarctica.and.Oceania\nE01006512                      0\nE01006513                      7\nE01006514                      5\nE01006515                      2\nE01006518                      4\nE01006519                      3\n\ntail(census2021)\n\n          Europe Africa Middle.East.and.Asia The.Americas.and.the.Caribbean\nE01033763   1302     68                  142                             11\nE01033764   2106     32                   49                             15\nE01033765   1277     21                   33                             17\nE01033766   1028     12                   20                              8\nE01033767   1003     29                   29                              5\nE01033768   1016     69                  111                             21\n          Antarctica.and.Oceania\nE01033763                      4\nE01033764                      0\nE01033765                      3\nE01033766                      7\nE01033767                      1\nE01033768                      6"
  },
  {
    "objectID": "openscience.html#summarise",
    "href": "openscience.html#summarise",
    "title": "OpenScience",
    "section": "Summarise",
    "text": "Summarise\nOr of the values of the table: ::: {.panel-tabset group=“language”} ## R\n\nsummary(census2021)\n\n     Europe         Africa       Middle.East.and.Asia\n Min.   : 731   Min.   :  0.00   Min.   :  1.00      \n 1st Qu.:1331   1st Qu.:  7.00   1st Qu.: 16.00      \n Median :1446   Median : 14.00   Median : 33.50      \n Mean   :1462   Mean   : 29.82   Mean   : 62.91      \n 3rd Qu.:1580   3rd Qu.: 30.00   3rd Qu.: 62.75      \n Max.   :2551   Max.   :484.00   Max.   :840.00      \n The.Americas.and.the.Caribbean Antarctica.and.Oceania\n Min.   : 0.000                 Min.   : 0.00         \n 1st Qu.: 2.000                 1st Qu.: 0.00         \n Median : 5.000                 Median : 1.00         \n Mean   : 8.087                 Mean   : 1.95         \n 3rd Qu.:10.000                 3rd Qu.: 3.00         \n Max.   :61.000                 Max.   :11.00"
  },
  {
    "objectID": "openscience.html#queries",
    "href": "openscience.html#queries",
    "title": "OpenScience",
    "section": "Queries",
    "text": "Queries\nIndex-based queries Condition-based queries Combining queries"
  },
  {
    "objectID": "openscience.html#sorting",
    "href": "openscience.html#sorting",
    "title": "OpenScience",
    "section": "Sorting",
    "text": "Sorting"
  },
  {
    "objectID": "openscience.html#visual-exploration",
    "href": "openscience.html#visual-exploration",
    "title": "OpenScience",
    "section": "Visual Exploration",
    "text": "Visual Exploration"
  },
  {
    "objectID": "openscience.html#python-4",
    "href": "openscience.html#python-4",
    "title": "OpenScience",
    "section": "Python",
    "text": "Python\n:::\nNote how the output is also a DataFrame object, so you can do with it the same things you would with the original table (e.g. writing it to a file).\nIn this case, the summary might be better presented if the table is “transposed”:\n\nRPython\n\n\n\nt(summary(census2021))\n\n                                                                \n    Europe                     Min.   : 731     1st Qu.:1331    \n    Africa                     Min.   :  0.00   1st Qu.:  7.00  \nMiddle.East.and.Asia           Min.   :  1.00   1st Qu.: 16.00  \nThe.Americas.and.the.Caribbean Min.   : 0.000   1st Qu.: 2.000  \nAntarctica.and.Oceania         Min.   : 0.00    1st Qu.: 0.00   \n                                                                \n    Europe                     Median :1446     Mean   :1462    \n    Africa                     Median : 14.00   Mean   : 29.82  \nMiddle.East.and.Asia           Median : 33.50   Mean   : 62.91  \nThe.Americas.and.the.Caribbean Median : 5.000   Mean   : 8.087  \nAntarctica.and.Oceania         Median : 1.00    Mean   : 1.95   \n                                                                \n    Europe                     3rd Qu.:1580     Max.   :2551    \n    Africa                     3rd Qu.: 30.00   Max.   :484.00  \nMiddle.East.and.Asia           3rd Qu.: 62.75   Max.   :840.00  \nThe.Americas.and.the.Caribbean 3rd Qu.:10.000   Max.   :61.000  \nAntarctica.and.Oceania         3rd Qu.: 3.00    Max.   :11.00   \n\n\n\n\n\n\n\n\nCreate new columns Delete columns"
  },
  {
    "objectID": "openscienceDIY.html#data-preparation",
    "href": "openscienceDIY.html#data-preparation",
    "title": "Do-It-Yourself",
    "section": "Data preparation",
    "text": "Data preparation\nBefore you can set off on your data journey, the dataset needs to be read, and there’s a couple of details we will get out of the way so it is then easier for you to start working.\nThe data are published on a Google Sheet you can check out at:\nhttps://docs.google.com/spreadsheets/d/1EAx8_ksSCmoWW_SlhFyq2QrRn0FNNhcg1TtDFJzZRgc/edit?hl=en#gid=1\nAs you will see, each row includes casualties recorded month by month, split by Taliban, Civilians, Afghan forces, and NATO.\nTo read it into a Python session, we need to slightly modify the URL to access it into:\n\nPythonR\n\n\n\n\n\n\n\n\n\nNote how we split the url into three lines so it is more readable in narrow screens. The result however, stored in url, is the same as one long string.\nThis allows us to read the data straight into a DataFrame, as we have done in the previous session:\n\nPythonR\n\n\n\n\n\n\n\n\n\n\n\nNote also we use the skiprows=[0, -1] to avoid reading the top (0) and bottom (-1) rows which, if you check on the Google Sheet, involves the title of the table.\nNow we are good to go!"
  },
  {
    "objectID": "environ.html#website-software",
    "href": "environ.html#website-software",
    "title": "Environment",
    "section": "Website Software",
    "text": "Website Software\nTo reproduce the code in the book, you need the most recent version of Quarto, R and relevant packages. These can be installed following the instructions provided in our R installation guide. Quarto (1.2.280) can be downloaded from the Quarto website, it may already be installed when you download R and R Studio."
  }
]