# Lab {#sec-spatial-data-lab .unnumbered}

```{r}
#| include: false
#knitr::opts_chunk$set(message = FALSE, warning = FALSE)
# install python packages needed for this document:
#pkgs = c("geopandas", "shapely", "pandas", "rasterio", "matplotlib", "folium", "mapclassify")
#reticulate::py_install(pkgs)
```

In this lab, we will learn how to load, manipulate and visualize spatial data. In some senses, spatial data are usually included simply as "one more column" in a table. However, *spatial is special* sometimes and there are few aspects in which geographic data differ from standard numerical tables. In this session, we will extend the skills developed in the previous one about non-spatial data, and combine them. In the process, we will discover that, although with some particularities, dealing with spatial data in R and Python largely resembles dealing with non-spatial data.

## Installing packages

We will start by loading core packages for working with spatial data. See detailed description of [R](https://r.geocompx.org/spatial-class) and [Python](https://geographicdata.science/book/notebooks/03_spatial_data.html).

::: {.panel-tabset group="language"}
## R

```{r message=FALSE}
# Load the 'sf' library, which stands for Simple Features, used for working with spatial data.
library(sf)
# Load the 'tidyverse' library, a collection of packages for data manipulation and visualization.
library(tidyverse)
# Load the 'tmap' library, which is used for creating thematic maps and visualizing spatial data.
library(tmap)
# The 'readr' library provides a fast and user-friendly way to read data from common formats like CSV.
library(readr)
# Converts Between GeoJSON and simple feature objects
library(geojsonsf) 
# Using data from OpenStreetMap (OSM)
library(osmdata)
```

## Python

```{python}
#import pandas as pd
#from shapely import Point
#import geopandas as gpd
```
:::

## Datasets

Today we are going to go to London. We will be playing around with different datasets loading them both locally and dynamically from the web. You can download data manually, keep a copy on your computer, and load them from there.

### Creating geographic data

First we will use the following commands create geographic datasets *from scratch* representing coordinates of some famous locations in London. Most projects start with pre-generated data, but it's useful to create datasets to understand data structures.

::: {.panel-tabset group="language"}
## R

```{r}
poi_df = tribble(
  ~name, ~lon, ~lat,
  "The British Museum",        -0.1459604, 51.5045975,
  "Big Ben",    -0.1272057, 51.5007325,
  "King's Cross", -0.1319481, 51.5301701,
  "The Natural History Museum",     -0.173734, 51.4938451
)
poi_sf = sf::st_as_sf(poi_df, coords = c("lon", "lat"), crs = "EPSG:4326")
```

## Python

```{python}
#poi = gpd.GeoDataFrame([
#    {"name": "The British Museum",        "geometry": Point(-0.1459604, 51.5045975)},
#    {"name": "Big Ben",    "geometry": Point(-0.1272057, 51.5007325)},
#    {"name": "King's Cross", "geometry": Point(-0.1319481, 51.5301701)},
#    {"name": "The Natural History Museum",     "geometry": Point(-0.173734, 51.4938451)},
#], crs=4326)
```
:::

### Polygons

Now let's look at the different types of geographical data starting with polygons. We will use a dataset that contains the boundaries of the districts of London. We can read it into an object named districts.

::: {.panel-tabset group="language"}
We first import the district shapefile use `read_sf`, we then plot it to make sure we are seeing it 'correctly'. We us `$geometry` to plot just the geometry, if we don't include `$geometry` R will plot the first 9 columns and if the dataset is large this is not advisable.

```{r}
districts <- read_sf("data/London/Polygons/districts.shp")

plot(districts$geometry) # Create a simple plot
```

## Python
:::

### Lines

We them import a `geojson` file of roads in London and plot it.

::: {.panel-tabset group="language"}
## R

```{r}
a_roads <- read_sf("data/London/Lines/a_roads.shp")
#a_roads <- geojson_sf("data/London/Lines/a_roads.geojson")

plot(a_roads$geometry)
```

## Python
:::

### Points

We can also import point files. So far, we have imported `shapefiles` and `geojsons`, but we can also obtain data from urls like in the [Open Science lab]() or other sources like **OpenStreetMap**. Both `R` and `Python` have libraries that allow us to query OpenStreetMap.

::: {.panel-tabset group="language"}
## R

```{r build_query}
osm_q_sf <- opq("Greater London, U.K.") %>% # searching only in Greater London
    add_osm_feature(key = "building", value = "museum") %>% #adding osm data that is tagged as a museum
  osmdata_sf () # transforming to sf object
```

The structure of osmdata objects are clear from their default print method, illustrated using the museum example. We will use them shortly.

```{r}
osm_q_sf  
```

## Python

In Python we will use osmnx. Note that we use the method pois_from_place, which queries for points of interest (POIs, or pois) in a particular place (London in this case). In addition, we can specify a set of tags to delimit the query. We use this to ask only for amenities of the type "..."

```{python}

```
:::

You do not need to know at this point what happens behind the scenes when we run these lines but, if you are curious, we are making a query to OpenStreetMap (almost as if you typed "museums in London, UK" within Google Maps) and getting the response as a table of data, instead of as a website with an interactive map. Pretty cool, huh?

Note the code cell above requires internet connectivity.

**Important**: Be careful, if you query too much data, your environment is likely to get stuck.

## Inspecting Spatial Data

### Inspecting `Dataframes`

Just like a `Dataframe` (see the OpenScience Lab), we can inspect the data (attributes table) within this spatial object. The most direct way to get from a file to a quick visualization of the data is by loading it and calling the `plot` command. Let's start by inspecting the data like we did for non sptaial `dataframes`.

We can see our data is very similar to a traditional, non-spatial `DataFrame`, but with an additional column called geometry.

::: {.panel-tabset group="language"}
## R

```{r}
head(districts) # the command "head" reads the first 5 rows of the data
```

We can inspect the object in different ways :

```{r}
districts[1,] # read first row
districts[,1] # read first column
districts[1,1] #read first row, first column: 00AA

# variable can be called using the operator $
districts$DIST_NAME #read the column "DIST_NAME"
```

We can read or create subsets :

```{r}
# dataframe can be subsetted using conditional statement
# read the rows which have "City of London" as value for DIST_NAME
districts[districts$DIST_NAME== "City of London",] 
```

## Python
:::

Let's start by plotting London in a colour and adding Hackney (a district) in a different colour.

::: {.panel-tabset group="language"}
## R

Let's start by plotting London in a colour and adding Hackney (a district) in a different colour.

```{r}
# plot london in grey
plot(districts$geometry, col = "lightgrey")

# Add city of London in turquoise to the map
plot(districts[districts$DIST_NAME == "Hackney", ]$geometry, # select city of london
     col = "turquoise",
     add = T) # add to the existing map
```

Some guidance on colours in R can be found [here](https://bookdown.org/hneth/ds4psy/D-3-apx-colors-basics.html).

How to reset a plot:

```{r, class.source = "fold-show"}
plot(districts$geometry, reset = T) # reset
```

## Python
:::

## Styling plots

It is possible to tweak many aspects of a plot to customize if to particular needs. In this section, we will explore some of the basic elements that will allow us to obtain more compelling maps.

**Note**: some of these variations are very straightforward while others are more intricate and require tinkering with the internal parts of a plot. They are not necessarily organized by increasing level of complexity.

### Plotting different layers

We first start by plotting one layer over another

::: {.panel-tabset group="language"}
## R

```{r}
plot(districts$geometry)
plot(a_roads$geometry, add=T) # note the `add=T` is adding the second layer.
```

Or use the `ggplot` package for something a bit fancier

```{r}

ggplot() +
 geom_sf(data = districts, color = "black") +  # Plot districts with black outline
  geom_sf(data = a_roads, color = "brown") +  # Plot roads with brown color and 50% transparency
  theme_minimal() 
```

## Python
:::

### Changing transparency

The intensity of color of a polygon can be easily changed through the alpha attribute in plot. This is specified as a value betwee zero and one, where the former is entirely transparent while the latter is the fully opaque (maximum intensity):

::: {.panel-tabset group="language"}
## R

```{r}
ggplot() +
  geom_sf(data = districts, fill = NA, color = "black") +  # Plot districts with black outline & no fill (NA)
  geom_sf(data = a_roads, color = "brown", alpha = 0.5) +  # Plot roads with brown color and 50% transparency
  theme_minimal()
```

## Python
:::

### Removing axes

Although in some cases, the axes can be useful to obtain context, most of the times maps look and feel better without them. Removing the axes involves wrapping the plot into a figure, which takes a few more lines of aparently useless code but that, in time, it will allow you to tweak the map further and to create much more flexible designs.

::: {.panel-tabset group="language"}
## R

```{r}

ggplot() +
  geom_sf(data = districts, fill = NA, color = "black") +  # Plot districts with black outline & no fill (NA)
  geom_sf(data = a_roads, color = "brown", alpha = 0.5) +  # Plot roads with brown color and 50% transparency
  theme(line = element_blank(), # remove tick marks
        rect = element_blank(), # remove background
        axis.text=element_blank()) # remove x and y axis
  # theme_void() # could also be used instead of the 3 above lines 

```

For more on themes in `ggplot` see [here](https://ggplot2.tidyverse.org/reference/ggtheme.html)

## Python
:::

### Adding a title

Adding a title is an extra line, if we are creating the plot within a figure, as we just did. To include text on top of the figure:

::: {.panel-tabset group="language"}
## R

```{r}
ggplot() +
  geom_sf(data = districts, fill = NA, color = "black") +  # Plot districts with black outline & no fill (NA)
  geom_sf(data = a_roads, color = "brown", alpha = 0.5) +  # Plot roads with brown color and 50% transparency
  theme_void() + # 
  ggtitle("Some London Roads") #add ggtitle
```

## Python
:::

### Changing what border lines look like

Border lines sometimes can distort or impede proper interpretation of a map. In those cases, it is useful to know how they can be modified. Let us first see the code to make the lines thicker and black, and then we will work our way through the different steps:

::: {.panel-tabset group="language"}
## R

```{r}

ggplot() +
  geom_sf(data = districts, fill = NA, color = "black") +  
  geom_sf(data = a_roads, color = "brown", alpha = 0.5) + 
  geom_sf(data = poi_sf, color = "blue", size = 3) + # size adjusts size of visualization
  theme_void() +
  ggtitle("Some London Roads") #add ggtitle


```

# Python

Although not too complicated, the way to access borders in geopandas is not as straightforward as it is the case for other aspects of the map, such as size or frame.
:::

### Labelling

Labeling maps is of paramount importance as it is often key when presenting data analysis and visualization. Properly labeled maps enables readers to effectively analyze and interpret spatial data.

::: {.panel-tabset group="language"}
## R

Here we are using `geom_sf_text` to add data, specifically the distrct name, to the centre of each District in a specific size.

```{r plotdata2}
ggplot() +
  geom_sf(data = districts,
          fill = "gray95") +
  geom_sf_text(data = districts,
               aes(label = DIST_NAME),
               fun.geometry = sf::st_centroid, size=2) +
  theme_void()

```

`geom_sf_text()` and `geom_sf_label()` can also be used to achieve similar effects.

## Python
:::

## Coordinate reference Systems

Coordindate reference systems (CRS) are the way geographers and cartographers represent a three-dimentional objects, such as the round earth, on a two-dimensional plane, such as a piece of paper or a computer screen. If the source data contain information on the CRS of the data, we can modify this.

First we need to retrieve the CRS from the vector data.

::: {.panel-tabset group="language"}
## R

```{r retrieve crs}
st_crs(districts) # retrieve coordinate reference system from object
```

The `st_crs` function also has one helpful feature -- we can retrieve some additional information about the used CRS. For example, try to run:

```{r}
st_crs(districts)$IsGeographic # to check is the CRS is geographic or not
st_crs(districts)$units_gdal # to find out the CRS units
st_crs(districts)$srid # extracts its SRID (when available)
st_crs(districts)$proj4string # extracts the proj4string representation
```

## Python

```{python}
```

As we can see, there is information stored about the reference system: it is using the standard British projection (British National Grid), which is expressed in meters. There are also other less decipherable parameters but we do not need to worry about them right now.
:::

If we want to modify this and "reproject" the polygons into a different CRS, the quickest way is to find the EPSG code online (epsg.io is a good one, although there are others too). For example, if we wanted to transform the dataset into lat/lon coordinates, we would use its EPSG code, 4326 (CRS's name "WGS84"):

::: {.panel-tabset group="language"}
## R

In cases when a coordinate reference system (CRS) is missing or the wrong CRS is set, the st_set_crs() function can be used:

```{r}
districts_4326 = st_transform(districts, "EPSG:4326") # set CRS
# districts_4326 <- st_transform(districts_4326, crs = 4326)

```

## Python
:::

CRSs are also very useful if we obtain data that is in a csv, has coordinates but needs to be transformed to a spatial datafrane. For example we have some London housing transactions we want to import and use.

::: {.panel-tabset group="language"}
## R

We want to transform the .csv in a `sf` object with the `st_as_sf` function using the coordinates stored in columns 17 and 18, and then we set the dataframe CRS to the British National Grid (EPSG:27700) using the `st_set_crs` function.

```{r}
housesales <- read.csv("data/London/Tables/housesales.csv") # import housesales data from csv

# 3 commands: 
housesales_filtered = filter(housesales,price < 500000)
housesales_sf <- st_as_sf(housesales_filtered, coords = c(17,18)) # denote columns which have the coordinates
housesales_clean <- st_set_crs(housesales_sf, 27700)# set crs to British National Grid 
```

As we've seen in [open science](https://pietrostefani.github.io/gds/openscience.html), we can do consecutive operations using `dplyr` pipes `%>%`, they are used to simplify syntax. Pipes allow to perform successive operations on dataframes in one command! More info [here](https://seananderson.ca/2014/09/13/dplyr-intro/).

```{r}
# all one in go and one output
housesales_clean = housesales %>% # select the main object
  filter(price < 500000) %>% # remove values above 500,000
  st_as_sf(coords = c(17,18)) %>% # # denote columns which have the coordinates
  st_set_crs(27700) # set crs to British National Grid
```

## Python
:::

### Zooming in or out

It's important to know what CRS your data is in if you want to create zoomed versions of your maps. [BBox finder](http://bboxfinder.com/#0.000000,0.000000,0.000000,0.000000) is a useful tool to identify coordinates in `EPSG:4326`.

Here for example we are zooming in to some of the point we created at the beginning of the lab.

::: {.panel-tabset group="language"}
## R

```{r}
ggplot() + 
 geom_sf(data = districts_4326$geometry) + 
  geom_sf(data = poi_sf$geometry, fill = 'red') +
  coord_sf(xlim = c(-0.180723,-0.014212), ylim = c(51.476668,51.532337)) +
   theme_void()

```

## Python
:::

## Manipulating Spatial Tables

Once we have an understanding of how to visually display spatial information contained, let us see how it can be combined with the operations related to manipulating non-spatial tabular data. Essentially, the key is to realize that a geographical `dataframes` contain most of its spatial information in a single column named geometry, but the rest of it looks and behaves exactly like a non-spatial `dataframes` (in fact, it is). This concedes them all the flexibility and convenience that we saw in manipulating, slicing, and transforming tabular data, with the bonus that spatial data is carried away in all those steps. In addition, geo `dataframes` also incorporate a set of explicitly spatial operations to combine and transform data. In this section, we will consider both.

Geo `dataframes` come with a whole range of traditional GIS operations built-in. Here we will run through a small subset of them that contains some of the most commonly used ones.

### Area

One of the spatial aspects we often need from polygons is their area. "How big is it?" is a question that always haunts us when we think of countries, regions, or cities. To obtain area measurements, first make sure the `dataframe` you are working with is projected. If that is the case, you can calculate areas as follows:

::: {.panel-tabset group="language"}
## R

We had already checked that district was projected to the British National Grid

```{r}
districts <- districts %>%
  mutate(area = st_area(.)/1000000) # calculate area and make it km2
```

## Python
:::

### Length

Similarly, an equally common question with lines is their length. Also similarly, their computation is relatively straightforward, provided that our data are projected.

::: {.panel-tabset group="language"}
## R

```{r}
a_roads <- a_roads %>%
  mutate(street_length = st_length(geometry)) # calculate street length in metres
```

If you check the `dataframe` you will see the lengths.

## Python
:::

### Centroids

Sometimes it is useful to summarize a polygon into a single point and, for that, a good candidate is its centroid (almost like a spatial analogue of the average).

::: {.panel-tabset group="language"}
## R

```{r warning=FALSE}
# Create a dataframe with centroids
centroids_df <- districts %>%
  st_centroid()
```

Plot the centroids

```{r}
ggplot() +
  geom_sf(data = districts) +  # Plot the districts segments
  geom_sf(data = centroids_df, color = "red", size = 2) +  # Plot the centroids in red
  theme_minimal()
```

## Python
:::

### Buffers and selecting by location

::: {.panel-tabset group="language"}
## R

Here, we first select by expression the Hackney district and then we create a 1km buffer around it with the `st_buffer()` function from the `sf` package.

```{r}
# Select a district of London and make new object
hackney = districts[districts$DIST_NAME== "Hackney",] 
plot(hackney$geometry)

# buffer
hackney_buffer <- st_buffer(hackney, 1000)

plot(hackney_buffer$geometry)
plot(hackney$geometry, add=T)
```

## Python
:::

### Join districts with educational level data

::: {.panel-tabset group="language"}
## R

```{r class.source = "fold-show"}

# import qualifications data from csv
qualifications2001_df <- read.csv("data/London/Tables/qualifications2001_2.csv")

# take a quick look at the table by reading the first 5 lines
head(qualifications2001_df)
```

-   Install the `dplyr` package, which is a must have package for data cleaning. More info can be found [here](https://dplyr.tidyverse.org/). `dplyr` is a part of the tidyverse!

-   Join merge two datasets `join(x, y)`.

    -   `left_join` returns all rows from x (`districts`), and all columns from x (`districts`) and y (`qualifications2001`)
    -   `inner join` returns all rows from x where there are matching values in y, and all columns from x and y)
    -   `right join` returns all rows from x, and all columns from x and y)
    -   `full_join` returns all rows and all columns from both x and y)

-   Merge the data from the `districts` shapefile and the qualifications from the csv file

-   Join `districts` data to `qualifications2001` using district identifiers called `DIST_CODE` in districts and `Zone_Code` in `qualifications2001_df`

```{r class.source = "fold-show"}

#join
districts <- left_join(districts, 
                       qualifications2001_df, 
                       by=c("DIST_CODE"="Zone_Code"))

# tidyverse alternative with pipe operator %>%

districts_tidy <- districts %>%
  left_join(qualifications2001_df, by=c("DIST_CODE"="Zone_Code"))

# check the first rows of the merged data table
head(districts)
```

Now, as in Workshop 2, let's create the share of people with level 4 qualification, i.e. create the new variable `Level4p` equal to the number of people with level4 qualification divided by total population:

```{r class.source = "fold-show"}

districts <- districts %>%
  mutate(Level4p = Level4/Population1674)

```

## Python
:::

## Saving maps to figures

::: {.panel-tabset group="language"}
## R

https://intro2r.com/export-plots.html

```{r}
dir.create("maps") # create a file to put your maps
```

```{r}
pdf("maps/london_test.pdf") # Opening the graphical device
plot(districts$geometry)
plot(housesales_clean$geometry, add=TRUE) 
dev.off() #Closing the graphical device
```

```{r}
ggsave("maps/map3.pdf")
ggsave("maps/map3_1.png", width = 4, height = 4)
ggsave("maps/map3_2.png", width = 20, height = 20, units = "cm")
#https://ggplot2.tidyverse.org/reference/ggsave.html
```

## Python
:::

## Adding base layers from web sources

Add in

## Interactive maps

::: {.panel-tabset group="language"}
## R

```{r}
library(leaflet)
popup = c("The British Museum", "Big Ben", "King's Cross", "The Natural History Museum")
leaflet() %>%
  addProviderTiles("CartoDB.Positron") %>%
  addMarkers(lng = c(-0.1459604, -0.1272057, -0.1319481, -0.173734),
             lat = c(51.5045975, 51.5007325, 51.5301701, 51.4938451), 
             popup = popup)
```

## Python
:::

## Additional resources
