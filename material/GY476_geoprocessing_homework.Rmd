---
title: "GY476_geoprocessing_homework"
author: "Elisabetta Pietrostefani and Louise Bernard"
date: "7/10/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(sf)
library(raster)
library(ggplot2)
library(dplyr)
library(viridis)
```

## Load and map data

Exercise 1: Find the correct command to load your data

```{r importdata}
#Import London districts and housesales data

# add the polygons of London to the environment
london <- XX(dsn = "data/London/Polygons/districts.shp")

# import housesales data from csv
housesales <- XX("data/London/Tables/housesales.csv")
```

Exercise 2: Create spatial data points

``` {r createspatialpts}
# create spatial points
housesales <- st_as_sf(housesales, XX) # create pts from coordinates
```

Exercise 3: Set the right CRS

``` {r transform}
# change the coordinate system to british national grid
housesales <-  st_set_crs(housesales, 27700)
```

Exercise 4: Create a map of London

``` {r plotdata}
# map London
map1 <- ggplot()+
  XX
map1
```

Exercise 5: Add the housesales points

``` {r addpts}
# add housing transactions data
map1 +  XX
```

## Spatial join

Exercise 6: Create a spatial join of the district polygons and housesales points

``` {r spatialjoin}
# spatial overlay between points and polygons
housesales_districts <- st_join(polygons, points)

# read the first lines of the attribute table
head(XX)
```

## Summarizing data 

Exercise 7: Create a summary of the number of housesales and the average price at the district level


``` {r aggregate}
# aggregate at ward level
housesales_districts_agg <- housesales_districts %>% 
  group_by(XX) %>% # group at district level
  summarise(count_sales = n(),  # create count
            mean_price = mean(XX)) # average price
head(housesales_districts_agg)
```


``` {r mapoutput}
# map housesales by wards
map2 <- ggplot()+
  geom_sf(data = housesales_districts_agg, inherit.aes = FALSE, aes(fill = mean_price)) +
  xlab("") +
  ylab("")
map2
```

## Re-aggregating at a different level

Exercise 8: Improve that map to visualize population better

``` {r reaggregatingdata}
# Import 1851 parishes
parishes <- read_sf(dsn = "data/week4_homework/london_parish_1851.shp")

# I randomely generate population data from the 1851 parishes
set.seed(12345678)
parishes$population <- runif(dim(parishes)[1], min=100, max=10000) 
plot(parishes[, "population"])


```

```{r visualinspection}
# let's overlay the two shapefiles
# we want to get 1851 population data into today's districts
plot(london$geometry, border="blue")
plot(parishes$geometry, border = "red", add= TRUE)
```

Exercise 9: Find the command for the spatial intersection of the `sf` package

``` {r calculategeometry}
# calculate area
london$area_district <- st_area(london) / 1000000
parishes$area_parish <- st_area(parishes) / 1000000

# intersectpolygons
parishes_districts <- XX(london, parishes)
plot(parishes_districts$geometry)

# calculate area
parishes_districts$area_inter <- st_area(parishes_districts) / 1000000
```

Exercise 10: Summarize the intersected area at the district level

``` {r summarizeagain}
# check the union results
inter_df <- parishes_districts %>%
  group_by(XX) %>% # group by districts
  summarise(area_district_check = sum(area_inter)) %>% # calculate the total area by ward
  st_drop_geometry() %>%
  left_join(london, c("DIST_CODE", "DIST_NAME"))

# check 
head(inter_df)

# the polygons do not perfectly overlap (e.g. borders of the Tames); the area of the re-aggregated districts are systematically smaller than the original
```

Exercise 11: Summarize the intersected area at the parish level


```{r reaggregate}

# first we need to know how much of the old parishses has been intersected
inter_agg <- parishes_districts %>%
  st_drop_geometry() %>%
  group_by(XX) %>%
  summarise(area_intersected = sum(area_inter))
```

Exercise 12: Summarize the parish population at the district level

``` {r newpopulation}
# second we calculate the share of the intersected polygon for each parish 
# then we use it to aggregate at the district level
parishes_districts_join <- parishes_districts %>%
  st_drop_geometry() %>%
  left_join(inter_agg[, c("name", "area_intersected")]) %>%
  mutate(share_parish = area_inter/area_intersected) %>%
  group_by(XX) %>%
  summarise_at("population", list(population = ~sum(. * share_parish))) %>%
  inner_join(london) %>%
  st_as_sf()
```

Exercise 13: Improve the map

``` {r plotresults}
# plot the results
plot(parishes_districts_join[, "population"])

# check it makes sense
sum(parishes$population)
sum(parishes_districts_join$population)

```

## Raster operations

Exercise 14: Find the command to calculate the slope of the `raster` package

``` {r rasters}
# import elevation data
elevation <- raster("data/Lebanon/DEM_Leb_projected.tif")

# calculate slope
slope <- XX
plot(slope)
```

Exercise 15: Reclassify the elevation to create the flood risk area (elevation under 10m)

``` {r floodrisk}
# flood risk: find area with a elevation less than 10
flood_risk <- calc(elevation, fun= function(x) ifelse(x<XX, 1, 0))
plot(flood_risk)
```

Exercise 16: Load the household points from the survey (Lebanon folder)

``` {r extract}
# sample 
households <- XX

# point data: calculate elevation at points' coordinates
housesales_elevation <- raster::extract(elevation,
                                households)

# attach elevation at each point to the original housesales dataframe
households <- cbind(households, housesales_elevation)
head(households)
 
```
